# -*- coding: utf-8 -*-
"""tests/test_agents.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u_RwfekK-iJ-zCLk8F-ST4P64rxrp95x
"""

import logging

import pytest
from src.reverse import agents
from src.reverse import main_enterprise


def test_run_agent_uses_configured_and_explicit_model(monkeypatch, caplog):
    called = []

    def fake_chat(*, model, messages, **kwargs):
        called.append((model, messages))
        return {"message": {"content": f"response-from-{model}"}}

    monkeypatch.setattr(agents.ollama, "chat", fake_chat)

    caplog.set_level(logging.INFO)

    agent_name = "Inspector"
    system_message = "Provide a detailed review."
    user_prompt = "Summarize the findings."

    returned_agent, response = agents.run_agent(agent_name, system_message, user_prompt)
    assert returned_agent == agent_name
    expected_default = main_enterprise.get_settings().default_model
    assert called[0][0] == expected_default
    assert response == f"response-from-{expected_default}"
    assert any("finished" in record.message for record in caplog.records)

    caplog.clear()

    returned_agent_custom, response_custom = agents.run_agent(
        agent_name,
        system_message,
        user_prompt,
        model="custom-model",
    )
    assert returned_agent_custom == agent_name
    assert called[1][0] == "custom-model"
    assert response_custom == "response-from-custom-model"
    assert any("finished" in record.message for record in caplog.records)

    # Verify messages forwarded correctly
    first_messages = called[0][1]
    assert first_messages[0] == {"role": "system", "content": system_message}
    assert first_messages[1] == {"role": "user", "content": user_prompt}